{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:09.465666Z",
     "start_time": "2019-10-14T14:46:08.749419Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:09.534946Z",
     "start_time": "2019-10-14T14:46:09.467836Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load saved data\n",
    "with open('/home/alex/data/project_2_datard3.pkl', 'rb') as picklefile:\n",
    "    data = pickle.load(picklefile)\n",
    "with open('/home/alex/data/project_2_datard4.pkl', 'rb') as picklefile:\n",
    "    data2 = pickle.load(picklefile)         \n",
    "with open('/home/alex/data/project_2_datard5.pkl', 'rb') as picklefile:\n",
    "    data3 = pickle.load(picklefile)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:09.727796Z",
     "start_time": "2019-10-14T14:46:09.536704Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(data), pd.DataFrame(data2), pd.DataFrame(data3)])\n",
    "# drop observations that have the same release ID\n",
    "df.drop_duplicates(subset = 'id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:09.809639Z",
     "start_time": "2019-10-14T14:46:09.730016Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.set_index(['release', 'id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:09.834802Z",
     "start_time": "2019-10-14T14:46:09.811963Z"
    }
   },
   "outputs": [],
   "source": [
    "# impute missing release dates and ratings with mean value\n",
    "df['release_date'] = df['release_date'].fillna(1996)\n",
    "df['rating'] = df['rating'].fillna(4.1)\n",
    "\n",
    "df['style'] = df['style'].fillna('')\n",
    "df['ask_price'] = df['ask_price'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Dates to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:10.122019Z",
     "start_time": "2019-10-14T14:46:09.836866Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert dates to numbers\n",
    "df.release_date = df.release_date.apply(lambda x: int(x))\n",
    "\n",
    "df.last_sold = df.last_sold.apply(lambda x: dt.datetime.strptime(x, '%d %b %y'))\n",
    "df.last_sold = df.last_sold.apply(lambda x: x.toordinal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop features that are high cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:10.136640Z",
     "start_time": "2019-10-14T14:46:10.124939Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(labels=['artist','label','format_details'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bin other categorical features and dummify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:10.214463Z",
     "start_time": "2019-10-14T14:46:10.139407Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "formatcounts = df['format'].value_counts()\n",
    "otherformats = list(formatcounts[formatcounts<100].index)\n",
    "df['format'] = df['format'].replace(otherformats, 'Other')\n",
    "\n",
    "countrycounts = df.country.value_counts()\n",
    "othercountries = list(countrycounts[countrycounts<100].index)\n",
    "df.country = df.country.replace(othercountries, 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:10.240004Z",
     "start_time": "2019-10-14T14:46:10.215816Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['format','country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as base case data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:10.263714Z",
     "start_time": "2019-10-14T14:46:10.241582Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/home/alex/data/project_2_basecase.pkl', 'wb') as picklefile:\n",
    "                pickle.dump(df, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create encoding for genre with increasing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:10.991506Z",
     "start_time": "2019-10-14T14:46:10.265979Z"
    }
   },
   "outputs": [],
   "source": [
    "df2=df.copy()\n",
    "#create genre tags\n",
    "# since we are splitting by comma, genres with commas in them need to be changed\n",
    "df2['genre']=df2['genre'].replace('Folk, World, & Country', 'FolkWorldCountry', regex=True)\n",
    "# extract unique genres from genre series\n",
    "genreset = set()\n",
    "for row in df2['genre']:\n",
    "    for item in row.split(','):\n",
    "        genreset.add(item.strip())\n",
    "#create new features for each unique genre\n",
    "for i in genreset:\n",
    "    df2[i]=0\n",
    "# each genre gets encoded according to its order in the list: first_genre=1, second=2, etc.\n",
    "for row in df2.itertuples():\n",
    "    for idx, item in enumerate(row.genre.split(',')):\n",
    "        df2.at[row.Index, item.strip()] = idx+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:11.003591Z",
     "start_time": "2019-10-14T14:46:10.993392Z"
    }
   },
   "outputs": [],
   "source": [
    "# no need for this column anymore\n",
    "df2.drop('genre',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:11.014226Z",
     "start_time": "2019-10-14T14:46:11.005013Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.drop(['ask_price','highest','lowest'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:11.028388Z",
     "start_time": "2019-10-14T14:46:11.015720Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df2[(df2['median']<200)&(df2['median']>0.15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:11.050868Z",
     "start_time": "2019-10-14T14:46:11.030214Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/home/alex/data/project_2_genretags.pkl', 'wb') as picklefile:\n",
    "                pickle.dump(df2, picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create encoding with increasing weights for style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:12.457418Z",
     "start_time": "2019-10-14T14:46:11.053665Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df2.copy()\n",
    "styleset = defaultdict(int)\n",
    "# Impute missing style data\n",
    "df5['style'] = df5['style'].fillna('None')\n",
    "# generate list of unique styles\n",
    "for row in df5['style']:\n",
    "    for item in row.split(','):\n",
    "        styleset[item.strip()]+=1\n",
    "# sort styels by count and keep the top fifty\n",
    "sortedstyles = []\n",
    "for item in styleset:\n",
    "    sortedstyles.append((styleset[item], item))\n",
    "popularstyles = []\n",
    "for i in sorted(sortedstyles, reverse=True)[:50]:\n",
    "    popularstyles.append(i[1])\n",
    "# Create columns for each style.\n",
    "for i in popularstyles:\n",
    "    # Need to check if the style is also a genre--would overwrite \n",
    "    # the above-defined genre weights. \n",
    "    if i not in genreset:\n",
    "        df5[i] = 0\n",
    "df5['Other_Style'] = 0\n",
    "# add encoding\n",
    "for row in df5.itertuples():\n",
    "    for idx, item in enumerate(row.style.split(',')):\n",
    "        # If it's not in the top 50 styles, add to other\n",
    "        if item.strip() not in popularstyles: \n",
    "            # if more than one style is in 'other', use highest index\n",
    "            if df5.at[row.Index, 'Other_Style'].any() == 0:\n",
    "                df5.at[row.Index, 'Other_Style'] = idx+1\n",
    "        # skip styles that are also genres\n",
    "        elif item.strip() in genreset:\n",
    "            continue\n",
    "        else:\n",
    "            df5.at[row.Index, item.strip()] = idx+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:12.480735Z",
     "start_time": "2019-10-14T14:46:12.458743Z"
    }
   },
   "outputs": [],
   "source": [
    "# no need for this column anymore\n",
    "df5.drop('style',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T14:46:12.505840Z",
     "start_time": "2019-10-14T14:46:12.482270Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/home/alex/data/project_2_styletags.pkl', 'wb') as picklefile:\n",
    "                pickle.dump(df5, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
